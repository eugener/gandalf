server:
  addr: ":8080"
  read_timeout: 30s
  write_timeout: 120s
  shutdown_timeout: 30s

database:
  dsn: "gandalf.db"

auth:
  admin_key: "${GANDALF_ADMIN_KEY}"

providers:
  - name: openai
    base_url: https://api.openai.com/v1
    api_key: "${OPENAI_API_KEY}"
    models:
      - gpt-4o
      - gpt-4o-mini
      - gpt-4.1
    priority: 1
    weight: 1
    timeout_ms: 30000

  - name: anthropic
    base_url: https://api.anthropic.com/v1
    api_key: "${ANTHROPIC_API_KEY}"
    models:
      - claude-sonnet-4-6
      - claude-haiku-4-5
    priority: 2
    weight: 1
    timeout_ms: 30000

  - name: gemini
    base_url: https://generativelanguage.googleapis.com/v1beta
    api_key: "${GEMINI_API_KEY}"
    models:
      - gemini-2.0-flash
      - gemini-2.0-pro
    priority: 3
    weight: 1
    timeout_ms: 30000

  - name: ollama
    base_url: http://localhost:11434
    api_key: ""
    models:
      - llama3
      - mistral
    priority: 4
    weight: 1
    timeout_ms: 60000
    enabled: false  # enable when Ollama is running locally

routes:
  - model_alias: gpt-4o
    targets:
      - provider: openai
        model: gpt-4o
        priority: 1
    strategy: priority

  - model_alias: gpt-4o-mini
    targets:
      - provider: openai
        model: gpt-4o-mini
        priority: 1
    strategy: priority

  - model_alias: gpt-4.1
    targets:
      - provider: openai
        model: gpt-4.1
        priority: 1
    strategy: priority

  - model_alias: claude-sonnet-4-6
    targets:
      - provider: anthropic
        model: claude-sonnet-4-6
        priority: 1
    strategy: priority

  - model_alias: claude-haiku-4-5
    targets:
      - provider: anthropic
        model: claude-haiku-4-5
        priority: 1
    strategy: priority

  - model_alias: gemini-2.0-flash
    targets:
      - provider: gemini
        model: gemini-2.0-flash
        priority: 1
    strategy: priority

  - model_alias: gemini-2.0-pro
    targets:
      - provider: gemini
        model: gemini-2.0-pro
        priority: 1
    strategy: priority

rate_limits:
  default_rpm: 60     # requests per minute per key (0 = unlimited)
  default_tpm: 100000 # tokens per minute per key (0 = unlimited)

cache:
  enabled: true
  max_size: 10000     # max cached responses
  default_ttl: 5m     # default TTL for cached responses

keys:
  - name: default-admin
    key: "${GANDALF_ADMIN_KEY}"
    org_id: default
    role: admin
